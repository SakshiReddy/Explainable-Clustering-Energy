{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Days Chosen: \n",
    "8th January 2014 <br>\n",
    "8th July 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags Chosen:\n",
    "\n",
    "1. TEMP: HOT/COLD\n",
    "2. LOCATION: ALBERMARLE/CHARLOTTESVILLE\n",
    "3. TOTSQFT: SMALL/MEDIUM/LARGE\n",
    "4. RMSP (Number of Rooms): 1-4, 5-8, 9+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cv_cold = pd.read_csv(r'VA540-20140108.csv')\n",
    "# df_cv_cold['temp'] = \"cold\"\n",
    "# df_cv_cold['loc'] = \"cv\"\n",
    "\n",
    "df_cv_hot = pd.read_csv(r'VA540-20140708.csv')\n",
    "df_cv_hot['temp'] = \"hot\"\n",
    "df_cv_hot['loc'] = \"cv\"\n",
    "\n",
    "# df_al_cold = pd.read_csv(r'VA003-20140108.csv')\n",
    "# df_al_cold['temp'] = \"cold\"\n",
    "# df_al_cold['loc'] = \"al\"\n",
    "\n",
    "df_al_hot = pd.read_csv(r'VA003-20140708.csv')\n",
    "df_al_hot['temp'] = \"hot\"\n",
    "df_al_hot['loc'] = \"al\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_cold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al_cold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.concat([df_cv_cold, df_cv_hot, df_al_cold, df_al_hot], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_cv_hot, df_al_hot], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [f'total_kwh_{i}' for i in range(1, 25)]\n",
    "# columns_to_keep.append('temp')\n",
    "columns_to_keep.append('loc')\n",
    "columns_to_keep.append('hid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.drop(columns=[col for col in combined_df.columns if col not in columns_to_keep])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_max_values = df.iloc[:, 1:-1].max(axis=1) # Find the maximum value for each row (axis=1)\n",
    "\n",
    "normalized_df = df.iloc[:, 1:-1].div(row_max_values, axis=0) # Divide each value by its corresponding max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_usage = normalized_df.iloc[:, 0:24].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means clustering\n",
    "\n",
    "wcss = []\n",
    "\n",
    "for n_clusters in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(hourly_usage)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the WCSS values against the number of clusters\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 11), wcss, marker='o')\n",
    "plt.title('Knee Method for Optimal Cluster Number')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS (Within-Cluster Sum of Squares)')\n",
    "plt.xticks(range(0, 11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(hourly_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = cluster_labels\n",
    "\n",
    "# Print the number of households in each cluster\n",
    "print(df['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(hourly_usage)\n",
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time array for the x-axis (24 hours)\n",
    "hours = np.arange(24)\n",
    "plt.figure(figsize=(10, 6))  # Adjust the width and height as needed\n",
    "\n",
    "# Plot each cluster's time series curve\n",
    "for i, center in enumerate(cluster_centers):\n",
    "    print(center.size)\n",
    "    plt.plot(hours, center, label=f'Cluster {i}')\n",
    "    \n",
    "plt.xticks(hours)  \n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Cluster Center')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recs = pd.read_csv(\"tag_data/recs2015_public_v2.csv\")\n",
    "df_dem = pd.read_csv(\"tag_data/va_hh_51003_51540.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF ALB HOUSEHOLDS IN DEM DATA \n",
    "prefix_count = (df['hid'].astype(str).str.startswith('51003')).sum()\n",
    "prefix_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_count = (df['hid'].astype(str).str.startswith('51540')).sum()\n",
    "prefix_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_dem, on='hid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['DOEID', 'TOTSQFT_EN', 'KOWNRENT']\n",
    "df_recs = df_recs[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_recs, merged_df, left_on='DOEID', right_on='rid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft_intervals = [400, 1500, 3500,10000]\n",
    "\n",
    "merged_df['SQFT_TAG'] = pd.cut(merged_df['TOTSQFT_EN'], bins=sqft_intervals, labels=['small', 'medium', 'large'], right=False)\n",
    "h_counts = merged_df['SQFT_TAG'].value_counts()\n",
    "\n",
    "\n",
    "print(h_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsp_intervals = [1,5,9,20]  \n",
    "\n",
    "merged_df['RMSP_TAG'] = pd.cut(merged_df['RMSP'], bins=rmsp_intervals, labels=['1-4', '5-8', '9+'], right=False)\n",
    "unit_counts = merged_df['RMSP_TAG'].value_counts()\n",
    "\n",
    "\n",
    "print(unit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybl_intervals = [1,4,6,8,float('inf')]  \n",
    "\n",
    "merged_df['YBL_TAG'] = pd.cut(merged_df['YBL'], bins=ybl_intervals, labels=['1959 or earlier','1960-1979','1980-1999','2000-2013'], right=False)\n",
    "unit_counts = merged_df['YBL_TAG'].value_counts()\n",
    "\n",
    "\n",
    "print(unit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hincp_intervals = [float('-inf'),40000,100000,160000,float('inf')]  \n",
    "\n",
    "merged_df['HINCP_TAG'] = pd.cut(merged_df['HINCP'], bins=hincp_intervals, labels=['Low income', 'Middle income', 'Upper-middle income','High income'], right=False)\n",
    "unit_counts = merged_df['HINCP_TAG'].value_counts()\n",
    "\n",
    "\n",
    "print(unit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNITS IN STRUCTURE\n",
    "\n",
    "unit_intervals = [0,2,3,4,10,float('inf')]  \n",
    "\n",
    "merged_df['BLD_TAG'] = pd.cut(merged_df['BLD'], bins=unit_intervals, labels=['Mobile Home/Trailer', 'One-family house A', 'One-family house D','Apts','Mobile Home/Trailer'], right=False, ordered=False)\n",
    "unit_counts = merged_df['BLD_TAG'].value_counts()\n",
    "\n",
    "\n",
    "print(unit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF PERSONS\n",
    "\n",
    "person_intervals = [1,2,3, float('inf')]  \n",
    "\n",
    "merged_df['NP_TAG'] = pd.cut(merged_df['NP'], bins=person_intervals, labels=['1','2', '2+'], right=False)\n",
    "per_counts = merged_df['NP_TAG'].value_counts()\n",
    "\n",
    "\n",
    "print(per_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['temp', 'loc', 'SQFT_TAG','RMSP_TAG','YBL_TAG','HINCP_TAG','BLD_TAG','NP_TAG']\n",
    "\n",
    "for col in cols:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(data=merged_df, x=col, order=merged_df[col].value_counts().index)\n",
    "    plt.title(f'Frequency Analysis of {col} (Whole Dataset)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.countplot(data=merged_df, x=col, hue='cluster', order=merged_df[col].value_counts().index)\n",
    "    plt.title(f'Frequency Analysis of {col} by Cluster')\n",
    "    plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify values you're looking for\n",
    "val1 = 0\n",
    "val2 = 0\n",
    "val3 = 0\n",
    "tag = \"NP_TAG\"\n",
    "y_1 = '1'\n",
    "y_2 = '2'\n",
    "y_3 = '2+'\n",
    "\n",
    "\n",
    "# Count the number of rows where ColumnA has x_value and ColumnB has y_value\n",
    "count_matching_rows_1 = len(merged_df[(merged_df['cluster'] == val1) & (merged_df[tag] == y_1)])\n",
    "count_matching_rows_2 = len(merged_df[(merged_df['cluster'] == val1) & (merged_df[tag] == y_2)])\n",
    "count_matching_rows_3= len(merged_df[(merged_df['cluster'] == val1) & (merged_df[tag] == y_3)])\n",
    "\n",
    "print(f\"Number of rows where ColumnA is {val1} and ColumnB is {y_1}: {count_matching_rows_1}\")\n",
    "print(f\"Number of rows where ColumnA is {val2} and ColumnB is {y_2}: {count_matching_rows_2}\")\n",
    "print(f\"Number of rows where ColumnA is {val3} and ColumnB is {y_3}: {count_matching_rows_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_input_file(df, alpha, beta, additional_tags):\n",
    "    \n",
    "    n = len(df)\n",
    "    K = df['cluster'].nunique()\n",
    "\n",
    "    unique_tags = set(df[additional_tags].values.flatten()) # Extract unique values from specified tag columns\n",
    "    N = len(unique_tags)\n",
    "    print(N)\n",
    "    print(unique_tags)\n",
    "\n",
    "    with open('data_hot_day.txt', 'w') as file:\n",
    "        file.write(f\"{n} {K} {N} {alpha} {beta}\\n\")\n",
    "        file.write(f\"Index Cluster {' '.join(unique_tags)}\\n\")\n",
    "\n",
    "        # Write the data items\n",
    "        for index, row in df.iterrows():\n",
    "            cluster_number = row['cluster']\n",
    "            tag_set = [1 if str(tag) in row[additional_tags].values else 0 for tag in unique_tags]\n",
    "\n",
    "            # Write the line for each data item\n",
    "            file.write(f\"{index + 1} {cluster_number} {' '.join(map(str, tag_set))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tags = ['loc', 'SQFT_TAG','RMSP_TAG','YBL_TAG','HINCP_TAG','BLD_TAG','NP_TAG']\n",
    "format_to_input_file(merged_df, alpha=4, beta=0, additional_tags=additional_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
